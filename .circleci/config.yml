version: 2.1

orbs:
  aws-cli: circleci/aws-cli@3.1
  terraform: circleci/terraform@3.2

jobs:
  lint-build-and-test:
    docker:
      - image: cimg/python:3.9
    steps:
      - checkout
      - run:
          name: Install deps
          command: |
            python -m venv venv
            . venv/bin/activate
            pip install --upgrade pip
            pip install -r python_scripts/requirements.txt
            pip install -r tests/test-requirements.txt
      - run:
          name: Run linting with Ruff
          command: |
            . venv/bin/activate
            ruff check .
      - run:
          name: Run project structure tests
          command: |
            . venv/bin/activate
            pytest tests/test_project_structure.py -v
      - run:
          name: Run DAG import tests
          command: |
            . venv/bin/activate
            pytest --cov=dags tests/ -v

  terraform-plan:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - aws-cli/setup
      - terraform/install:
          terraform_version: 1.5.7
      - run:
          name: Set up AWS credentials
          command: |
            if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ]; then
              echo "Missing required AWS environment variables"
              exit 1
            fi
            aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
            aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
            aws configure set default.region us-east-1
      - run:
          name: Create tfvars file
          command: |
            cd terraform
            echo "$TFVARS_JSON" > terraform.tfvars.json
      - run:
          name: Initialize Terraform
          command: |
            cd terraform
            terraform init
      - run:
          name: Run Terraform Plan
          command: |
            cd terraform
            terraform plan -out=tfplan -var-file=terraform.tfvars.json
      - persist_to_workspace:
          root: .
          paths:
            - terraform/
            - terraform/.terraform
            - terraform/tfplan
            - terraform/terraform.tfvars.json

  terraform-apply:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - aws-cli/setup
      - terraform/install:
          terraform_version: 1.5.7
      - attach_workspace:
          at: .
      - run:
          name: Apply Terraform Changes
          command: |
            cd terraform
            terraform apply -auto-approve tfplan
      - run:
          name: Get EC2 Public IP
          command: |
            cd terraform
            echo "Running terraform output command..."
            terraform output
            echo "Getting airflow_instance_public_ip..."
            EC2_IP=$(terraform output -raw airflow_instance_public_ip)
            echo "Raw EC2 IP value: '$EC2_IP'"
            if [ -z "$EC2_IP" ]; then
              echo "Failed to get EC2 public IP"
              exit 1
            fi
            echo "Retrieved EC2 public IP: $EC2_IP"
            # Store in a file that will be persisted (in the root directory)
            cd ..
            echo "$EC2_IP" > ec2_public_ip.txt
            # Set environment variable for current job
            echo "export EC2_PUBLIC_IP=$EC2_IP" >> $BASH_ENV
            # Set environment variable for next job using CircleCI's environment file
            echo "EC2_PUBLIC_IP=$EC2_IP" >> $BASH_ENV
      - persist_to_workspace:
          root: .
          paths:
            - terraform/
            - terraform/.terraform
            - terraform/tfplan
            - terraform/terraform.tfvars.json
            - ec2_public_ip.txt

  deploy:
    docker:
      - image: cimg/base:stable
    environment:
      EC2_PUBLIC_IP: "${EC2_PUBLIC_IP}"
      EC2_USERNAME: "ubuntu"
    steps:
      - checkout
      - attach_workspace:
          at: .
      - run:
          name: List workspace contents
          command: |
            echo "Current directory: $(pwd)"
            echo "Listing workspace contents:"
            ls -la
      - run:
          name: Load EC2 Public IP
          command: |
            echo "Looking for ec2_public_ip.txt in $(pwd)"
            if [ -f "ec2_public_ip.txt" ]; then
              EC2_IP=$(cat ec2_public_ip.txt)
              echo "Loaded EC2 IP from file: $EC2_IP"
              echo "export EC2_PUBLIC_IP=$EC2_IP" >> $BASH_ENV
            else
              echo "ec2_public_ip.txt not found in workspace"
              echo "Current directory contents:"
              ls -la
              exit 1
            fi
      - run:
          name: Verify EC2 Public IP
          command: |
            echo "Current EC2_PUBLIC_IP value: '$EC2_PUBLIC_IP'"
            if [ -z "$EC2_PUBLIC_IP" ]; then
              echo "EC2_PUBLIC_IP is not set"
              exit 1
            fi
            if [ "$EC2_PUBLIC_IP" = "\${EC2_PUBLIC_IP}" ]; then
              echo "EC2_PUBLIC_IP was not properly interpolated"
              exit 1
            fi
            echo "Using EC2 Public IP: $EC2_PUBLIC_IP"
      - run:
          name: Install rsync
          command: |
            sudo apt-get update
            sudo apt-get install -y rsync
      - add_ssh_keys:
          fingerprints:
            - "SHA256:XZxECDr5WBjd5eywDRnkjHe56yLY1848+WLb4Mvav18"
      - run:
          name: Deploy to EC2
          command: |
            # Create a temporary file with the environment variables JSON
            echo "$AIRFLOW_ENV_VARS_JSON" > airflow_env_vars.json

            # Verify SSH connection
            echo "Testing SSH connection to ${EC2_USERNAME}@${EC2_PUBLIC_IP}..."
            ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 ${EC2_USERNAME}@${EC2_PUBLIC_IP} 'echo "SSH connection successful"'

            # Deploy to EC2 and set up environment variables
            ssh -o StrictHostKeyChecking=no ${EC2_USERNAME}@${EC2_PUBLIC_IP} \<< 'EOF'
              # Create directory for environment variables if it doesn't exist
              sudo mkdir -p /opt/airflow-dbt-template/config
              sudo chown -R ${USER}:${USER} /opt/airflow-dbt-template

              # Create a script to load environment variables
              sudo tee /opt/airflow-dbt-template/config/load_env_vars.sh > /dev/null \<< 'EOSCRIPT'
              #!/bin/bash

              # Function to convert JSON to environment variables
              json_to_env() {
                local json_file=$1
                while IFS="=" read -r key value; do
                  # Remove quotes and export the variable
                  key=$(echo $key | tr -d '"')
                  value=$(echo $value | tr -d '"')
                  export "$key=$value"
                done < <(jq -r 'to_entries | .[] | "\(.key)=\(.value)"' "$json_file")
              }

              # Load environment variables from JSON
              if [ -f "/opt/airflow-dbt-template/config/airflow_env_vars.json" ]; then
                json_to_env "/opt/airflow-dbt-template/config/airflow_env_vars.json"
              fi
              EOSCRIPT

              # Make the script executable
              sudo chmod +x /opt/airflow-dbt-template/config/load_env_vars.sh
              sudo chown ${USER}:${USER} /opt/airflow-dbt-template/config/load_env_vars.sh
            EOF

            # Copy the environment variables JSON file to EC2
            scp -o StrictHostKeyChecking=no airflow_env_vars.json ${EC2_USERNAME}@${EC2_PUBLIC_IP}:/tmp/airflow_env_vars.json
            ssh -o StrictHostKeyChecking=no ${EC2_USERNAME}@${EC2_PUBLIC_IP} "sudo mv /tmp/airflow_env_vars.json /opt/airflow-dbt-template/config/ && sudo chown ${USER}:${USER} /opt/airflow-dbt-template/config/airflow_env_vars.json"

            # SSH into EC2 and restart services with new environment variables
            ssh -o StrictHostKeyChecking=no ${EC2_USERNAME}@${EC2_PUBLIC_IP} \<< 'EOF'
              # Install jq if not already installed
              if ! command -v jq &> /dev/null; then
                sudo apt-get update
                sudo apt-get install -y jq
              fi

              # Source the environment variables and restart services
              cd /opt/airflow-dbt-template/
              source config/load_env_vars.sh
              sudo docker compose down || echo "No containers to stop"
              sudo -E docker compose up -d
            EOF

workflows:
  version: 2
  ci-deploy:
    jobs:
      - lint-build-and-test
      - terraform-plan:
          requires:
            - lint-build-and-test
      - terraform-apply:
          requires:
            - terraform-plan
      - deploy:
          requires:
            - terraform-apply
          # filters:
          #   branches:
          #     only: main
