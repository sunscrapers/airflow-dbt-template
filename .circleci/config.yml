version: 2.1

orbs:
  aws-cli: circleci/aws-cli@3.1
  terraform: circleci/terraform@3.2

jobs:
  lint-build-and-test:
    docker:
      - image: cimg/python:3.9
    steps:
      - checkout
      - run:
          name: Install deps
          command: |
            python -m venv venv
            . venv/bin/activate
            pip install --upgrade pip
            pip install -r python_scripts/requirements.txt
            pip install -r tests/test-requirements.txt
      - run:
          name: Run linting with Ruff
          command: |
            . venv/bin/activate
            ruff check .
      - run:
          name: Run project structure tests
          command: |
            . venv/bin/activate
            pytest tests/test_project_structure.py -v
      - run:
          name: Run DAG import tests
          command: |
            . venv/bin/activate
            pytest --cov=dags tests/ -v

  terraform-plan:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - aws-cli/setup
      - terraform/install:
          terraform_version: 1.5.7
      - run:
          name: Set up AWS credentials
          command: |
            if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ]; then
              echo "Missing required AWS environment variables"
              exit 1
            fi
            aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
            aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
            aws configure set default.region us-east-1
      - run:
          name: Create tfvars file
          command: |
            cd terraform
            echo "$TFVARS_JSON" > terraform.tfvars.json
      - run:
          name: Initialize Terraform
          command: |
            cd terraform
            terraform init
      - run:
          name: Run Terraform Plan
          command: |
            cd terraform
            terraform plan -out=tfplan -var-file=terraform.tfvars.json
      - persist_to_workspace:
          root: .
          paths:
            - terraform/
            - terraform/.terraform
            - terraform/tfplan
            - terraform/terraform.tfvars.json

  terraform-apply:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - aws-cli/setup
      - terraform/install:
          terraform_version: 1.5.7
      - attach_workspace:
          at: .
      - run:
          name: Apply Terraform Changes
          command: |
            cd terraform
            terraform apply -auto-approve tfplan
      - run:
          name: Get EC2 Public IP
          command: |
            cd terraform
            EC2_IP=$(terraform output -raw airflow_instance_public_ip)
            if [ -z "$EC2_IP" ]; then
              echo "Failed to get EC2 public IP"
              exit 1
            fi
            echo "Retrieved EC2 public IP: $EC2_IP"
            echo "export EC2_PUBLIC_IP=$EC2_IP" >> $BASH_ENV
            echo "EC2_PUBLIC_IP=$EC2_IP" >> $CIRCLE_ENV
      - persist_to_workspace:
          root: .
          paths:
            - terraform/
            - terraform/.terraform
            - terraform/tfplan
            - terraform/terraform.tfvars.json

  deploy:
    docker:
      - image: cimg/base:stable
    environment:
      EC2_PUBLIC_IP: "${EC2_PUBLIC_IP}"
      EC2_USERNAME: "ubuntu"
    steps:
      - checkout
      - attach_workspace:
          at: .
      - run:
          name: Verify EC2 Public IP
          command: |
            if [ -z "$EC2_PUBLIC_IP" ]; then
              echo "EC2_PUBLIC_IP is not set"
              exit 1
            fi
            echo "Using EC2 Public IP: $EC2_PUBLIC_IP"
      - run:
          name: Install rsync
          command: |
            sudo apt-get update
            sudo apt-get install -y rsync
      - add_ssh_keys:
          fingerprints:
            - "SHA256:XZxECDr5WBjd5eywDRnkjHe56yLY1848+WLb4Mvav18"
      - run:
          name: Deploy to EC2
          command: |
            # Create a temporary file with the environment variables JSON
            echo "$AIRFLOW_ENV_VARS_JSON" > airflow_env_vars.json

            # Verify SSH connection
            echo "Testing SSH connection to ${EC2_USERNAME}@${EC2_PUBLIC_IP}..."
            ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 ${EC2_USERNAME}@${EC2_PUBLIC_IP} 'echo "SSH connection successful"'

            # Deploy to EC2 and set up environment variables
            ssh -o StrictHostKeyChecking=no ${EC2_USERNAME}@${EC2_PUBLIC_IP} << 'EOF'
              # Create directory for environment variables if it doesn't exist
              mkdir -p /opt/airflow-dbt-template/config

              # Create a script to load environment variables
              cat > /opt/airflow-dbt-template/config/load_env_vars.sh \<< 'EOSCRIPT'
              #!/bin/bash

              # Function to convert JSON to environment variables
              json_to_env() {
                local json_file=$1
                while IFS="=" read -r key value; do
                  # Remove quotes and export the variable
                  key=$(echo $key | tr -d '"')
                  value=$(echo $value | tr -d '"')
                  export "$key=$value"
                done < <(jq -r 'to_entries | .[] | "\(.key)=\(.value)"' "$json_file")
              }

              # Load environment variables from JSON
              if [ -f "/opt/airflow-dbt-template/config/airflow_env_vars.json" ]; then
                json_to_env "/opt/airflow-dbt-template/config/airflow_env_vars.json"
              fi
              EOSCRIPT

              # Make the script executable
              chmod +x /opt/airflow-dbt-template/config/load_env_vars.sh
            EOF

            # Copy the environment variables JSON file to EC2
            scp -o StrictHostKeyChecking=no airflow_env_vars.json ${EC2_USERNAME}@${EC2_PUBLIC_IP}:/opt/airflow-dbt-template/config/

            # SSH into EC2 and restart services with new environment variables
            ssh -o StrictHostKeyChecking=no ${EC2_USERNAME}@${EC2_PUBLIC_IP} \<< 'EOF'
              # Install jq if not already installed
              if ! command -v jq &> /dev/null; then
                sudo apt-get update
                sudo apt-get install -y jq
              fi

              # Source the environment variables and restart services
              cd /opt/airflow-dbt-template/
              source config/load_env_vars.sh
              sudo docker compose down || echo "No containers to stop"
              sudo -E docker compose up -d
            EOF

workflows:
  version: 2
  ci-deploy:
    jobs:
      - lint-build-and-test
      - terraform-plan:
          requires:
            - lint-build-and-test
      - terraform-apply:
          requires:
            - terraform-plan
      - deploy:
          requires:
            - terraform-apply
          # filters:
          #   branches:
          #     only: main
